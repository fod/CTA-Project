\documentclass[12pt, a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

\parindent=0pt % disables indentation
\parskip=12pt  % adds vertical space between paragraphs

\title{CTA Project}
\author{Fiachra O'Donoghue}

\begin{document}
    
\section{Introduction}

Formal definition of sorting and the property of being sorted\dots
Sorting: reorganising a list, A,such that if A\textsubscript{i} < A\textsubscript{j} then i < j must be true.


If there exists any pair of elements in a collection A, at positions \emph{i} and \emph{j}, such that \emph{i} < \emph{j} but A\textsubscript{i} > A\textsubscript{j} -- with respect to whatever comparator function is relevant -- that pair of elements is known as an inversion. The degree of disorder or "unsortedness" of a collection of elemetns is measured by the number of inversions present.

To be sorted: Each item in the collection is less than or equal to its successor.

Equal-valued elements must be contiguous; i.e. if A\textsubscript{i} = A\textsubscript{j} then there must be no k such that i < j < k and A\textsubscript{i} $\ne$ A\textsubscript{k}

The contents of a collection, A, must be the same before and after searching; i.e. the sorted collection A must be a permuattion fo the pre-sorted collection A.

<, =, $\ne$, and > can be interpreted in terms of mathematical equality or any othey arbtrary but well defined system of ordering. It should be possible to define a \emph{comparator function} which can take two elements, say \emph{a} and \emph{b}, and return a value based on whether \emph{a} < \emph{b}, \emph{a} > \emph{b}, or \emph{a} = \emph{b}.

Sorting algorithms, in general, operate independently of the precise definitions of \emph{less than}, \emph{greater than}, and \emph{equal to} differing instead in how they go about making comparisons between pairs of elements with the goal of a completely sorted collection.

The particular problem's defintion of equivalence is encoded in the comparator function and the precise nature of the comparator function is irrelevant to the sorting algorithm which merely requires a black box through which it can pass two values and which returns a codification of the equivalence of those values.

More concretely; the following pseudocode demonstrates a comparator function which for comparing numerical values.

\begin{algorithm}
\caption{A function for comparing numerical values}\label{euclid}
\begin{algorithmic}[1]
\Procedure{Comparator}{a, b}
\If {$a < b$} \Return -1
\EndIf
\If {$a = b$} \Return 0
\EndIf
\If {$a > b$} \Return 1
\EndIf
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection{Analysing algorithm complexity}

Some algorithms can have good time complexity but are not practical for certain kinds of input data, e.g. insertion sort performs poorly on lage datasets but extemely well on smaller ones.

Where an implementation requires the use of nested loops, in most cases this will indicate O(n\textsuperscript{2}) complexity.

\subsection{Sorting algorithm properties}

\subsubsection{Stability}

Stability is the property whereby two equally valued elements in the input collection maintain their positions with respect to one another in the output (sorted) collection. Stability is unlikely to be an important consideration when sorting a collection of simple objects such as numbers but, when there is satellite data, it can become important \cite[p. 170]{cormen01introduction}.

\subsubsection{Time efficiency}

\subsubsection{Memory efficiency}
In-place sorting: Only a fixed amount of memory over the size of n (size of input) required, regardless of size of n. Non-in-place algorithms generally need an amount of memory that increases monotonically with n.

\subsubsection{Suitability for a particular input}

e.g. Size of input, degree of sorting, domain of input (e.g. integers from 1 to 1000), memory requirements, storage location (e.g. external?)

\subsection{Comparison Sorts}

Only uses comaprison operators to order elements. A comparison based sorting algorithm orders a collection by comparing pairs of elements until the collection is sorted.

No comparison sorting algorithm can perform better than \emph{n log n} in the average or worst cases. Some non-comparison based sorting algorithms can, under certain circumstances, with better worst-case times than \emph{n log n}.

\section{Sorting Algorithms}

\subsection{Insertion sort}

Good for small lists and ones which are almost sorted because the inner loop only needs to iterate until it finds the insertion point. Running time in the case of an already sorted list is $\Omega$(n) because the inner loop will not have to run at all.

Often used in hybrid sorting algotrithms for its efficiency with small inputs.

\subsection{Heapsort}

A heap structure is a nearly complete binary tree (\cite[p. 128]{cormen01introduction}). The indices of the parent, left child, and right chaild can be calculated as parent = i/2, left child = 2i, and right child = 2i+1, where i is the index of the element. These can quickly be calculated by shifting bits (\cite[p. 128]{cormen01introduction})

Uses max heap -- at most a node is the value of its parent
\subsection{Quicksort}

Can perform badly if pivot consistently chosen which puts all or almost all elements in one or other of the sub arrays. For instance if 1st or last ais chosen and array is already nearly sorted. Median mgiht be better because best case is if the two sublists are roughly equal at each iteration.

Usual options: first, last, random, median

\subsection{Counting sort}

\subsection{Introsort}

Added insertion sort when partition size <= 20 


\section{Implementation \& Benchmarking}

Benchmarking: empirical method for comparing algorithm performance a postiori. Can be used to vaildate a priori / theoretical hypotheses

@max Use the min() rather than the average of the timings. That is a recommendation from me, from Tim Peters, and from Guido van Rossum. The fastest time represents the best an algorithm can perform when the caches are loaded and the system isn't busy with other tasks. All the timings are noisy -- the fastest time is the least noisy. It is easy to show that the fastest timings are the most reproducible and therefore the most useful when timing two different implementations.

https://www.oreilly.com/library/view/python-cookbook/0596001673/ch17.html -- Tim Peters on timing



\begin{tabular}{lrrrrrrrrrrrrr}
    \hline
                    &   100 &   250 &    500 &    750 &   1000 &    1250 &    2500 &     3750 &     5000 &     6250 &     7500 &     8750 &    10000 \\
    \hline
        insertion\_sort & 1.082 & 5.297 & 21.701 & 52.072 & 90.874 & 143.243 & 593.199 & 1318.3   & 2348.3   & 3640.56  & 5350.09  & 7300.5   & 9504.14  \\
        quicksort      & 0.28  & 0.874 &  1.937 &  3.609 &  4.716 &   6.322 &  17.591 &   32.529 &   53.89  &   76.678 &  104.856 &  133.81  &  175.071 \\
        heapsort       & 0.565 & 1.647 &  3.55  &  5.921 &  7.931 &  10.315 &  22.512 &   35.915 &   49.244 &   63.411 &   76.997 &   92.16  &  105.975 \\
        counting\_sort  & 0.091 & 0.174 &  0.335 &  0.477 &  0.663 &   0.805 &   1.642 &    2.311 &    2.971 &    3.712 &    4.384 &    5.001 &    5.772 \\
        introsort      & 0.295 & 0.797 &  1.476 &  2.577 &  3.029 &   3.487 &  10.094 &   24.093 &   37.677 &   46.581 &   56.788 &   69.493 &   80.566 \\
    \hline
\end{tabular}
        

\bibliography{report}
\bibliographystyle{ieeetr}

\end{document}